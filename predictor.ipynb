{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns\n",
    "'DATE, REPORT_TYPE, SOURCE, AWND, CDSD, CLDD, DSNW, DYHF, DYTS, DailyAverageDryBulbTemperature, DailyAverageStationPressure, DailyAverageWindSpeed, DailyCoolingDegreeDays, DailyDepartureFromNormalAverageTemperature, DailyHeatingDegreeDays, DailyMaximumDryBulbTemperature, DailyMinimumDryBulbTemperature, DailyPeakWindDirection, DailyPeakWindSpeed, DailyPrecipitation, DailySnowDepth, DailySnowfall, DailySustainedWindDirection, DailySustainedWindSpeed, DailyWeather, HDSD, HTDD, HourlyAltimeterSetting, HourlyDewPointTemperature, HourlyDryBulbTemperature, HourlyPrecipitation, HourlyPresentWeatherType, HourlyPressureChange, HourlyPressureTendency, HourlyRelativeHumidity, HourlySeaLevelPressure, HourlySkyConditions, HourlyStationPressure, HourlyVisibility, HourlyWetBulbTemperature, HourlyWindDirection, HourlyWindGustSpeed, HourlyWindSpeed, MonthlyDaysWithGT001Precip, MonthlyDaysWithGT010Precip, MonthlyDaysWithGT32Temp, MonthlyDaysWithGT90Temp, MonthlyDaysWithLT0Temp, MonthlyDaysWithLT32Temp, MonthlyDepartureFromNormalAverageTemperature, MonthlyDepartureFromNormalCoolingDegreeDays, MonthlyDepartureFromNormalHeatingDegreeDays, MonthlyDepartureFromNormalMaximumTemperature, MonthlyDepartureFromNormalMinimumTemperature, MonthlyDepartureFromNormalPrecipitation, MonthlyGreatestPrecip, MonthlyGreatestPrecipDate, MonthlyMaxSeaLevelPressureValue, MonthlyMaxSeaLevelPressureValueDate, MonthlyMaxSeaLevelPressureValueTime, MonthlyMaximumTemperature, MonthlyMeanTemperature, MonthlyMinSeaLevelPressureValue, MonthlyMinSeaLevelPressureValueDate, MonthlyMinSeaLevelPressureValueTime, MonthlyMinimumTemperature, MonthlySeaLevelPressure, MonthlyStationPressure, MonthlyTotalLiquidPrecipitation, NormalsCoolingDegreeDay, NormalsHeatingDegreeDay, REM, REPORT_TYPE.1, SOURCE.1, ShortDurationEndDate005, ShortDurationEndDate010, ShortDurationEndDate015, ShortDurationEndDate020, ShortDurationEndDate030, ShortDurationEndDate045, ShortDurationEndDate060, ShortDurationEndDate080, ShortDurationEndDate100, ShortDurationEndDate120, ShortDurationEndDate150, ShortDurationEndDate180, ShortDurationPrecipitationValue005, ShortDurationPrecipitationValue010, ShortDurationPrecipitationValue015, ShortDurationPrecipitationValue020, ShortDurationPrecipitationValue030, ShortDurationPrecipitationValue045, ShortDurationPrecipitationValue060, ShortDurationPrecipitationValue080, ShortDurationPrecipitationValue100, ShortDurationPrecipitationValue120, ShortDurationPrecipitationValue150, ShortDurationPrecipitationValue180, Sunrise, Sunset, MonthlyInd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import re\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropNaCols(df):\n",
    "    '''given a dataframe, drop all the columns with nothing but NaN'''\n",
    "    naColList = []\n",
    "    for ele in df.columns:\n",
    "        uniqueVals = list(df[ele].unique())\n",
    "        if len(uniqueVals) == 1:\n",
    "            naColList.append(ele)\n",
    "    return(df.drop(columns=naColList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadingType(df):\n",
    "    '''indicates whether the given row provides a monthly, daily, or hourly reading'''\n",
    "    \n",
    "    #get the different column types into separate lists\n",
    "    monthlyCols = [ele for ele in list(df.columns) if 'month' in ele.lower()]\n",
    "    dailyCols = [ele for ele in list(df.columns) if 'dai' in ele.lower()]\n",
    "    hourlyCols = [ele for ele in list(df.columns) if 'hour' in ele.lower()]\n",
    "\n",
    "    #create columns indicating whether a row contains monthly, daily, or hourly readings\n",
    "    boolMask_monthly = ~df[monthlyCols].isna()\n",
    "    df['monthlyInd'] = boolMask_monthly.sum(axis=1)\n",
    "\n",
    "    boolMask_daily = ~df[dailyCols].isna()\n",
    "    df['dailyInd'] = boolMask_daily.sum(axis=1)\n",
    "\n",
    "    boolMask_hourly = ~df[hourlyCols].isna()\n",
    "    df['hourlyInd'] = boolMask_hourly.sum(axis=1)\n",
    "\n",
    "    #if a row has more than one non-NaN value in a monthly column, the reading is monthly, else if more than one non-NaN value in a daily column, the reading is daily, else if more than one non-Nan value in an hourly column, the reading is hourly else indicate no valid readings for the row\n",
    "    df['ReadingType'] = ['monthly' if df.iloc[ele]['monthlyInd'] > 0 else 'daily' if df.iloc[ele]['dailyInd'] > 0 else 'hourly' if df.iloc[ele]['hourlyInd'] > 0 else 'noValidReading' for ele in range(df.shape[0])]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDataframes(df):\n",
    "    '''given a dataframe of labeled monthly, daily, and hourly readings, split the dataframe by those labels into component dataframes and load those to a dictionary labeled according to reading type'''\n",
    "    dfDict = {}\n",
    "    for ele in df['ReadingType'].unique():\n",
    "        dfDict[ele] = DropNaCols(df[df['ReadingType'] == ele]).reset_index(drop=True)\n",
    "    return dfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanWeatherDF(df):\n",
    "    '''given a dataframe of local weather data, do some cosmetic cleaning including...\n",
    "    1. remove uppercase from column names and add underscores between words\n",
    "    2. convert date column to datetime'''\n",
    "\n",
    "    #1. remove uppercase from column names and add underscores between words\n",
    "    new_column_names = []\n",
    "    for ele in list(df.columns):\n",
    "        if ele.isupper():\n",
    "            new_column_names.append(re.sub('([.])','_',ele.lower()))\n",
    "        else:\n",
    "            new_column_names.append(re.sub('([.])','_',re.sub('(?<!^)(?=[A-Z])', '_',ele).lower()))\n",
    "    df.columns = new_column_names\n",
    "\n",
    "    # convert date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up numerican columns, converting strings to digits, removing unnecessary strings, converting to floats\n",
    "def CleanHourlyColumns(df):\n",
    "    '''given a dataframe of hourly weather values, clean up the column values'''\n",
    "    numerical_columns = ['hourly_altimeter_setting','hourly_dew_point_temperature','hourly_dry_bulb_temperature','hourly_precipitation','hourly_pressure_change','hourly_pressure_tendency','hourly_relative_humidity','hourly_sea_level_pressure','hourly_station_pressure','hourly_visibility','hourly_wet_bulb_temperature','hourly_wind_direction','hourly_wind_gust_speed','hourly_wind_speed']\n",
    "\n",
    "    for ele in numerical_columns:\n",
    "        df[ele] = df[ele].replace('[A-Za-z*]','',regex=True).replace('',0).astype(float).fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning:\n",
      "\n",
      "Columns (21,27,28,29,30,31,36,37,38,42,43,49,50,52,54,57,59,60,61,62,64,115,118,120) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "df = pd.read_csv('3063831.csv')\n",
    "\n",
    "#add reading type column\n",
    "df = ReadingType(df)\n",
    "\n",
    "#clean up data\n",
    "df = DropNaCols(df)\n",
    "\n",
    "#next, put dataframe into separate dataframes depending on the type of reading\n",
    "dfDict = SplitDataframes(df)\n",
    "\n",
    "#clean up dataframes\n",
    "for ele in dfDict.values():\n",
    "    ele = CleanWeatherDF(ele)\n",
    "\n",
    "#for numerical columns in the hourly data, make them truly numerical\n",
    "dfDict['hourly'] = CleanHourlyColumns(dfDict['hourly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfDict['hourly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'report_type', 'source', 'hourly_altimeter_setting',\n",
       "       'hourly_dew_point_temperature', 'hourly_dry_bulb_temperature',\n",
       "       'hourly_precipitation', 'hourly_present_weather_type',\n",
       "       'hourly_pressure_change', 'hourly_pressure_tendency',\n",
       "       'hourly_relative_humidity', 'hourly_sea_level_pressure',\n",
       "       'hourly_sky_conditions', 'hourly_station_pressure', 'hourly_visibility',\n",
       "       'hourly_wet_bulb_temperature', 'hourly_wind_direction',\n",
       "       'hourly_wind_gust_speed', 'hourly_wind_speed', 'rem', 'report_type_1',\n",
       "       'source_1', 'hourly_ind'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['hourly_dew_point_temperature']\n",
    "y = df['hourly_dry_bulb_temperature']\n",
    "\n",
    "X_train, X_test, y_train, y_split = train_test_split(X, y, test_size=.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35420    38.0\n",
       "32878    67.0\n",
       "38189    42.0\n",
       "36928    36.0\n",
       "12180    57.0\n",
       "         ... \n",
       "19527    79.0\n",
       "24828    24.0\n",
       "20414    81.0\n",
       "9526     55.0\n",
       "10967    32.0\n",
       "Name: hourly_dry_bulb_temperature, Length: 33663, dtype: float64"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
